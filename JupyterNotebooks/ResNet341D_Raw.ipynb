{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e3cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 21:34:24.508856: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import scale\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65280bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fde0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.compat.v2.keras.utils.Sequence):\n",
    "    def __init__(self, data_path, list_files, list_ann_files, \n",
    "                 batch_size=64, dim=(3000,1), n_classes=5, shuffle=True):\n",
    "        # Constructor of the data generator.\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "        self.list_files = list_files\n",
    "        self.list_ann_files = list_ann_files\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.get_cnts() #Get the data count for each file        \n",
    "        self.on_epoch_end() #Initialize file indexes        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int((self.total_len+1) / self.batch_size)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        start = index*self.batch_size\n",
    "        end = min((index+1)*self.batch_size, self.total_len)\n",
    "        \n",
    "        X = np.empty((end - start,) + self.dim, dtype=np.float32)\n",
    "        y = np.empty((end - start,), dtype=np.int32)\n",
    "        \n",
    "        curr_file_idx, accum_start, accum_end = self.get_accum_idx(index)\n",
    "        \n",
    "        curr_file = self.list_files[self.file_indexes[curr_file_idx]]\n",
    "        curr_ann_file = self.list_ann_files[self.file_indexes[curr_file_idx]]\n",
    "        data_index = self.data_indexes[self.file_indexes[curr_file_idx]]\n",
    "        \n",
    "        if curr_file.startswith('SC'):\n",
    "            file_path = os.path.join(self.data_path, 'signals_SC_filtered', curr_file)\n",
    "            ann_path = os.path.join(self.data_path, 'annotations_SC', curr_ann_file)\n",
    "        else:\n",
    "            file_path = os.path.join(self.data_path, 'signals_ST_filtered', curr_file)\n",
    "            ann_path = os.path.join(self.data_path, 'annotations_ST', curr_ann_file)\n",
    "        \n",
    "        curr_np = np.load(file_path)\n",
    "        curr_ann = np.load(ann_path)\n",
    "        curr_np = curr_np[data_index]\n",
    "        curr_ann = curr_ann[data_index]\n",
    "        \n",
    "        X_1 = curr_np[start - accum_start:end - accum_start] \n",
    "        y_1 = curr_ann[start - accum_start:end - accum_start]\n",
    "        from_curr = min(accum_end - start, end - start)\n",
    "        X[:from_curr] = np.expand_dims(X_1, axis=-1)\n",
    "        y[:from_curr] = y_1\n",
    "        \n",
    "        if end > accum_end:\n",
    "            curr_file_idx += 1\n",
    "            accum_start = accum_end\n",
    "            accum_end += self.list_cnt[self.file_indexes[curr_file_idx]]\n",
    "            curr_file = self.list_files[self.file_indexes[curr_file_idx]]            \n",
    "            curr_ann_file = self.list_ann_files[self.file_indexes[curr_file_idx]]\n",
    "            data_index = self.data_indexes[self.file_indexes[curr_file_idx]]\n",
    "            \n",
    "            if curr_file.startswith('SC'):\n",
    "                file_path = os.path.join(self.data_path, 'signals_SC_filtered', curr_file)\n",
    "                ann_path = os.path.join(self.data_path, 'annotations_SC', curr_ann_file)\n",
    "            else:\n",
    "                file_path = os.path.join(self.data_path, 'signals_ST_filtered', curr_file)\n",
    "                ann_path = os.path.join(self.data_path, 'annotations_ST', curr_ann_file)\n",
    "                \n",
    "            curr_np = np.load(file_path)\n",
    "            curr_ann = np.load(ann_path)\n",
    "\n",
    "            curr_np = curr_np[data_index]\n",
    "            curr_ann = curr_ann[data_index]\n",
    "            \n",
    "            X_2 = curr_np[:end - accum_start]\n",
    "            y_2 = curr_ann[:end - accum_start]\n",
    "            X[from_curr:] = np.expand_dims(X_2, axis=-1)\n",
    "            y[from_curr:] = y_2\n",
    "        \n",
    "        '''\n",
    "        # Normalize data(MinMax)\n",
    "        rng = np.max(X, axis=1) - np.min(X, axis=1) #X shape: (B, 3000, 1), rng: (B, 1)\n",
    "        rng = np.expand_dims(rng, axis=1) #(B, 1, 1)\n",
    "        X = (X - np.expand_dims(np.min(X, axis=1),axis=1)) / (rng + 1e-8)\n",
    "        '''                \n",
    "        return X, y\n",
    "    \n",
    "    def get_accum_idx(self, index):\n",
    "        curr_file_idx = 0\n",
    "        accum_start = 0\n",
    "        accum_end = self.list_cnt[self.file_indexes[0]]\n",
    "        for i in range(len(self.file_indexes)):\n",
    "            if index * self.batch_size < accum_end:\n",
    "                curr_file_idx = i                \n",
    "                break            \n",
    "            accum_start += self.list_cnt[self.file_indexes[i]]\n",
    "            accum_end += self.list_cnt[self.file_indexes[i+1]]\n",
    "        \n",
    "        return curr_file_idx, accum_start, accum_end\n",
    "        \n",
    "    def on_epoch_end(self):        \n",
    "        self.curr_file_idx = 0\n",
    "        # This function is called at the end of each epoch.\n",
    "        self.file_indexes = np.arange(len(self.list_files)) #This is necessary to shuffle files\n",
    "        self.data_indexes = [np.arange(cnt) for cnt in self.list_cnt]\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.file_indexes)\n",
    "            for i in range(len(self.list_cnt)):\n",
    "                np.random.shuffle(self.data_indexes[i]) \n",
    "            \n",
    "        #self.accum_start = 0 \n",
    "        #self.accum_end = self.list_cnt[self.file_indexes[0]]                 \n",
    "            \n",
    "    def get_cnts(self):\n",
    "        list_cnt = []\n",
    "        for f in self.list_ann_files:\n",
    "            if f.startswith('SC'):\n",
    "                #file_path = os.path.join(self.data_path, 'signals_SC_filtered', curr_file)\n",
    "                ann_path = os.path.join(self.data_path, 'annotations_SC', f)\n",
    "            else:\n",
    "                #file_path = os.path.join(self.data_path, 'signals_ST_filtered', curr_file)\n",
    "                ann_path = os.path.join(self.data_path, 'annotations_ST', f)\n",
    "            temp_np = np.load(ann_path)\n",
    "            cnt_data = temp_np.shape[0] \n",
    "            list_cnt.append(cnt_data)\n",
    "            \n",
    "        self.list_cnt = list_cnt\n",
    "        self.total_len = sum(list_cnt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df9c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_path = os.getcwd() + '/'\n",
    "PROCESSED_DATA_PATH = os.path.join('/home','aiot','data','origin_npy')\n",
    "save_signals_path = os.path.join(PROCESSED_DATA_PATH,'signals_SC_filtered')\n",
    "save_annotations_path = os.path.join(PROCESSED_DATA_PATH,'annotations_SC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457af95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_annotations_npy(dirname, filename):\n",
    "    search_filename = filename.split('-')[0][:-2]\n",
    "    file_list = os.listdir(dirname)\n",
    "    filenames = [file for file in file_list if search_filename in file if file.endswith('.npy')]\n",
    "\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d64b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_HT1D = (3000,1) \n",
    "n_classes=6\n",
    "epochs = 50\n",
    "bs = 64\n",
    "BASE_LEARNING_RATE = 1e-3\n",
    "list_files = [f for f in os.listdir(save_signals_path) if f.endswith('.npy')]\n",
    "\n",
    "save_signals_path_ST = os.path.join(PROCESSED_DATA_PATH,'signals_ST_filtered')\n",
    "save_annotations_path_ST = os.path.join(PROCESSED_DATA_PATH,'annotations_ST')\n",
    "\n",
    "list_files_ST = [f for f in os.listdir(save_signals_path_ST) if f.endswith('.npy')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e173803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_list(filepath):\n",
    "    import csv\n",
    "    with open(filepath, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        list_filepath = [row[0] for row in spamreader]\n",
    "    return list_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc54e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SC_train = os.path.join('/home','aiot','data','origin_npy','SC_train.csv')\n",
    "#SC_test = os.path.join('/home','aiot','data','origin_npy','SC_test.csv')\n",
    "\n",
    "#list_files_train = read_csv_to_list(SC_train)\n",
    "#list_files_test = read_csv_to_list(SC_test)\n",
    "\n",
    "#list_files_train = [f + '.npy' for f in list_files_train]\n",
    "#list_files_test = [f + '.npy' for f in list_files_test]\n",
    "\n",
    "split_cnt = int(len(list_files) * 0.7)\n",
    "list_files_train = list_files[:split_cnt]\n",
    "list_files_test = list_files[split_cnt:]\n",
    "\n",
    "split_cnt = int(len(list_files_ST) * 0.7)\n",
    "list_files_train += list_files_ST[:split_cnt]\n",
    "list_files_test += list_files_ST[split_cnt:]\n",
    "#list_ann_files_train = list_ann_files[:split_cnt]\n",
    "#list_ann_files_test = list_ann_files[split_cnt:]\n",
    "\n",
    "\n",
    "list_ann_files_train = []\n",
    "list_ann_files_test = []\n",
    "for f in list_files_train:\n",
    "    if f.startswith('SC'):\n",
    "        ann_file = match_annotations_npy(save_annotations_path, f)\n",
    "    else:\n",
    "        ann_file = match_annotations_npy(save_annotations_path_ST, f)\n",
    "    list_ann_files_train.append(ann_file[0])\n",
    "    \n",
    "for f in list_files_test:\n",
    "    if f.startswith('SC'):\n",
    "        ann_file = match_annotations_npy(save_annotations_path, f)\n",
    "    else:\n",
    "        ann_file = match_annotations_npy(save_annotations_path_ST, f)\n",
    "    list_ann_files_test.append(ann_file[0])\n",
    "\n",
    "#list_files_train = list_files[:5]\n",
    "#list_files_test = list_files[80:90]\n",
    "#list_ann_files_train = list_ann_files[0:5]\n",
    "#list_ann_files_test = list_ann_files[80:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac79f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(PROCESSED_DATA_PATH, list_files_train, list_ann_files_train, \n",
    "                          batch_size=bs, dim=dim_HT1D, n_classes=n_classes, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5097eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(PROCESSED_DATA_PATH, list_files_test, list_ann_files_test, \n",
    "                          batch_size=bs, dim=dim_HT1D, n_classes=n_classes, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e989162c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom collections import defaultdict\\ncnt_class = defaultdict(int)\\nfor x, y in train_generator:\\n    unique, counts = np.unique(y, return_counts=True)\\n    for i, cnt in zip(unique, counts):\\n        cnt_class[i] += cnt\\ncnt_class_np = np.array(list(cnt_class.values()))\\nclass_weight = sum(cnt_class_np)/(n_classes * cnt_class_np)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate class weight\n",
    "# Tested loss with class weight, but doesn't improve the accuracy\n",
    "'''\n",
    "from collections import defaultdict\n",
    "cnt_class = defaultdict(int)\n",
    "for x, y in train_generator:\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    for i, cnt in zip(unique, counts):\n",
    "        cnt_class[i] += cnt\n",
    "cnt_class_np = np.array(list(cnt_class.values()))\n",
    "class_weight = sum(cnt_class_np)/(n_classes * cnt_class_np)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24801c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet1D\n",
    "import resnet1D_Ahmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245f94bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'resnet1D_Ahmed' from '/home/keondopark/sleep/resnet1D_Ahmed.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib \n",
    "importlib.reload(resnet1D)  # Python 3.4+\n",
    "importlib.reload(resnet1D_Ahmed)  # Python 3.4+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c8e932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 21:34:52.492822: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-22 21:34:53.366768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-02-22 21:34:53.367738: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-22 21:34:53.999954: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-02-22 21:34:54.000013: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-02-22 21:34:54.139737: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-22 21:34:54.363688: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-22 21:34:54.612791: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-02-22 21:34:54.802884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-02-22 21:34:54.808759: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-02-22 21:34:54.813191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-02-22 21:34:54.814317: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 21:34:54.817665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-02-22 21:34:54.821155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-02-22 21:34:54.821245: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-22 21:34:56.552517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-22 21:34:56.552568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-02-22 21:34:56.552575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-02-22 21:34:56.563804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22318 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "#model = resnet1D.ResNet34(input_shape=(3000,1), num_classes=n_classes)\n",
    "model = resnet1D_Ahmed.eegnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ee1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        bs = y_pred.shape[0]\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        #loss = -K.sum(loss, -1)\n",
    "        loss = -K.sum(loss) / bs\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a584aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=BASE_LEARNING_RATE)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "#loss_fn = weighted_categorical_crossentropy(weights=class_weight) #class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9275e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_lr(epoch):\n",
    "    lr = BASE_LEARNING_RATE\n",
    "    for _ in range(epoch // 10):\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    optimizer.learning_rate = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40130015",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpt_ResNet341D_ST', max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "322dec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if manager.latest_checkpoint:\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    start_epoch = ckpt.step.numpy()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d2271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 9--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 21:34:58.830049: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-02-22 21:35:00.588938: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2022-02-22 21:35:05.532750: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-02-22 21:35:05.532817: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2022-02-22 21:35:05.534020: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-02-22 21:35:05.534478: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-02-22 21:35:05.753353: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-02-22 21:35:07.275354: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-02-22 21:35:08.290422: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4930 / 4939] Training loss: 0.322008, Training acc: 0.883\n",
      "Training time: 1159.52 sec \n",
      "[2130 / 2139] test loss: 0.710047, test accuracy: 0.806\n",
      "Eval time: 150.72 sec\n",
      "Saved checkpoint for step 11: ./ckpt_ResNet341D_ST/ckpt-10\n",
      "-------------------- Epoch 10--------------------\n",
      "[4930 / 4939] Training loss: 0.337886, Training acc: 0.877\n",
      "Training time: 1122.17 sec \n",
      "[2130 / 2139] test loss: 0.540484, test accuracy: 0.847\n",
      "Eval time: 139.01 sec\n",
      "Saved checkpoint for step 12: ./ckpt_ResNet341D_ST/ckpt-11\n",
      "-------------------- Epoch 11--------------------\n",
      "[4930 / 4939] Training loss: 0.325218, Training acc: 0.881\n",
      "Training time: 1117.91 sec \n",
      "[2130 / 2139] test loss: 0.534706, test accuracy: 0.847\n",
      "Eval time: 137.06 sec\n",
      "Saved checkpoint for step 13: ./ckpt_ResNet341D_ST/ckpt-12\n",
      "-------------------- Epoch 12--------------------\n",
      "[4930 / 4939] Training loss: 0.320388, Training acc: 0.882\n",
      "Training time: 1117.07 sec \n",
      "[2130 / 2139] test loss: 0.537012, test accuracy: 0.848\n",
      "Eval time: 139.24 sec\n",
      "Saved checkpoint for step 14: ./ckpt_ResNet341D_ST/ckpt-13\n",
      "-------------------- Epoch 13--------------------\n",
      "[4930 / 4939] Training loss: 0.316466, Training acc: 0.883\n",
      "Training time: 1124.99 sec \n",
      "[2130 / 2139] test loss: 0.542217, test accuracy: 0.847\n",
      "Eval time: 139.46 sec\n",
      "Saved checkpoint for step 15: ./ckpt_ResNet341D_ST/ckpt-14\n",
      "-------------------- Epoch 14--------------------\n",
      "[4930 / 4939] Training loss: 0.313434, Training acc: 0.884\n",
      "Training time: 1115.41 sec \n",
      "[2130 / 2139] test loss: 0.544325, test accuracy: 0.847\n",
      "Eval time: 141.96 sec\n",
      "Saved checkpoint for step 16: ./ckpt_ResNet341D_ST/ckpt-15\n",
      "-------------------- Epoch 15--------------------\n",
      "[4930 / 4939] Training loss: 0.310873, Training acc: 0.885\n",
      "Training time: 1126.05 sec \n",
      "[2130 / 2139] test loss: 0.547305, test accuracy: 0.848\n",
      "Eval time: 144.67 sec\n",
      "Saved checkpoint for step 17: ./ckpt_ResNet341D_ST/ckpt-16\n",
      "-------------------- Epoch 16--------------------\n",
      "[4930 / 4939] Training loss: 0.308350, Training acc: 0.886\n",
      "Training time: 1116.05 sec \n",
      "[2130 / 2139] test loss: 0.551570, test accuracy: 0.848\n",
      "Eval time: 139.41 sec\n",
      "Saved checkpoint for step 18: ./ckpt_ResNet341D_ST/ckpt-17\n",
      "-------------------- Epoch 17--------------------\n",
      "[4930 / 4939] Training loss: 0.306318, Training acc: 0.887\n",
      "Training time: 1123.47 sec \n",
      "[2130 / 2139] test loss: 0.553753, test accuracy: 0.848\n",
      "Eval time: 140.99 sec\n",
      "Saved checkpoint for step 19: ./ckpt_ResNet341D_ST/ckpt-18\n",
      "-------------------- Epoch 18--------------------\n",
      "[4930 / 4939] Training loss: 0.304439, Training acc: 0.887\n",
      "Training time: 1127.12 sec \n",
      "[2130 / 2139] test loss: 0.552711, test accuracy: 0.849\n",
      "Eval time: 142.22 sec\n",
      "Saved checkpoint for step 20: ./ckpt_ResNet341D_ST/ckpt-19\n",
      "-------------------- Epoch 19--------------------\n",
      "[4930 / 4939] Training loss: 0.302646, Training acc: 0.888\n",
      "Training time: 1119.96 sec \n",
      "[2130 / 2139] test loss: 0.555337, test accuracy: 0.849\n",
      "Eval time: 139.30 sec\n",
      "Saved checkpoint for step 21: ./ckpt_ResNet341D_ST/ckpt-20\n",
      "-------------------- Epoch 20--------------------\n",
      "[4930 / 4939] Training loss: 0.310986, Training acc: 0.884\n",
      "Training time: 1116.37 sec \n",
      "[2130 / 2139] test loss: 0.517786, test accuracy: 0.858\n",
      "Eval time: 139.07 sec\n",
      "Saved checkpoint for step 22: ./ckpt_ResNet341D_ST/ckpt-21\n",
      "-------------------- Epoch 21--------------------\n",
      "[4930 / 4939] Training loss: 0.306120, Training acc: 0.886\n",
      "Training time: 1122.62 sec \n",
      "[2130 / 2139] test loss: 0.515959, test accuracy: 0.858\n",
      "Eval time: 139.81 sec\n",
      "Saved checkpoint for step 23: ./ckpt_ResNet341D_ST/ckpt-22\n",
      "-------------------- Epoch 22--------------------\n",
      "[4930 / 4939] Training loss: 0.305261, Training acc: 0.886\n",
      "Training time: 1119.72 sec \n",
      "[2130 / 2139] test loss: 0.516106, test accuracy: 0.858\n",
      "Eval time: 139.59 sec\n",
      "Saved checkpoint for step 24: ./ckpt_ResNet341D_ST/ckpt-23\n",
      "-------------------- Epoch 23--------------------\n",
      "[4930 / 4939] Training loss: 0.304817, Training acc: 0.886\n",
      "Training time: 1117.88 sec \n",
      "[2130 / 2139] test loss: 0.516175, test accuracy: 0.858\n",
      "Eval time: 139.04 sec\n",
      "Saved checkpoint for step 25: ./ckpt_ResNet341D_ST/ckpt-24\n",
      "-------------------- Epoch 24--------------------\n",
      "[4930 / 4939] Training loss: 0.304426, Training acc: 0.887\n",
      "Training time: 1126.32 sec \n",
      "[2130 / 2139] test loss: 0.516437, test accuracy: 0.858\n",
      "Eval time: 141.84 sec\n",
      "Saved checkpoint for step 26: ./ckpt_ResNet341D_ST/ckpt-25\n",
      "-------------------- Epoch 25--------------------\n",
      "[4930 / 4939] Training loss: 0.304024, Training acc: 0.886\n",
      "Training time: 1117.94 sec \n",
      "[2130 / 2139] test loss: 0.516830, test accuracy: 0.858\n",
      "Eval time: 139.47 sec\n",
      "Saved checkpoint for step 27: ./ckpt_ResNet341D_ST/ckpt-26\n",
      "-------------------- Epoch 26--------------------\n",
      "[4930 / 4939] Training loss: 0.303802, Training acc: 0.887\n",
      "Training time: 1116.05 sec \n",
      "[2130 / 2139] test loss: 0.517785, test accuracy: 0.858\n",
      "Eval time: 139.00 sec\n",
      "Saved checkpoint for step 28: ./ckpt_ResNet341D_ST/ckpt-27\n",
      "-------------------- Epoch 27--------------------\n",
      "[4930 / 4939] Training loss: 0.303269, Training acc: 0.887\n",
      "Training time: 1127.08 sec \n",
      "[2130 / 2139] test loss: 0.517883, test accuracy: 0.858\n",
      "Eval time: 142.68 sec\n",
      "Saved checkpoint for step 29: ./ckpt_ResNet341D_ST/ckpt-28\n",
      "-------------------- Epoch 28--------------------\n",
      "[4930 / 4939] Training loss: 0.303027, Training acc: 0.887\n",
      "Training time: 1117.17 sec \n",
      "[2130 / 2139] test loss: 0.518256, test accuracy: 0.858\n",
      "Eval time: 139.44 sec\n",
      "Saved checkpoint for step 30: ./ckpt_ResNet341D_ST/ckpt-29\n",
      "-------------------- Epoch 29--------------------\n",
      "[4930 / 4939] Training loss: 0.303065, Training acc: 0.887\n",
      "Training time: 1116.78 sec \n",
      "[2130 / 2139] test loss: 0.518953, test accuracy: 0.858\n",
      "Eval time: 138.74 sec\n",
      "Saved checkpoint for step 31: ./ckpt_ResNet341D_ST/ckpt-30\n",
      "-------------------- Epoch 30--------------------\n",
      "[4930 / 4939] Training loss: 0.303338, Training acc: 0.886\n",
      "Training time: 1125.64 sec \n",
      "[2130 / 2139] test loss: 0.516560, test accuracy: 0.859\n",
      "Eval time: 141.76 sec\n",
      "Saved checkpoint for step 32: ./ckpt_ResNet341D_ST/ckpt-31\n",
      "-------------------- Epoch 31--------------------\n",
      "[4930 / 4939] Training loss: 0.302783, Training acc: 0.887\n",
      "Training time: 1119.43 sec \n",
      "[2130 / 2139] test loss: 0.515421, test accuracy: 0.859\n",
      "Eval time: 139.14 sec\n",
      "Saved checkpoint for step 33: ./ckpt_ResNet341D_ST/ckpt-32\n",
      "-------------------- Epoch 32--------------------\n",
      "[4930 / 4939] Training loss: 0.302267, Training acc: 0.887\n",
      "Training time: 1117.18 sec \n",
      "[2130 / 2139] test loss: 0.515035, test accuracy: 0.859\n",
      "Eval time: 140.31 sec\n",
      "Saved checkpoint for step 34: ./ckpt_ResNet341D_ST/ckpt-33\n",
      "-------------------- Epoch 33--------------------\n",
      "[4930 / 4939] Training loss: 0.302426, Training acc: 0.887\n",
      "Training time: 1132.57 sec \n",
      "[2130 / 2139] test loss: 0.514854, test accuracy: 0.859\n",
      "Eval time: 143.49 sec\n",
      "Saved checkpoint for step 35: ./ckpt_ResNet341D_ST/ckpt-34\n",
      "-------------------- Epoch 34--------------------\n",
      "[4930 / 4939] Training loss: 0.302316, Training acc: 0.887\n",
      "Training time: 1124.51 sec \n",
      "[2130 / 2139] test loss: 0.514705, test accuracy: 0.859\n",
      "Eval time: 140.93 sec\n",
      "Saved checkpoint for step 36: ./ckpt_ResNet341D_ST/ckpt-35\n",
      "-------------------- Epoch 35--------------------\n",
      "[4930 / 4939] Training loss: 0.302100, Training acc: 0.887\n",
      "Training time: 1136.57 sec \n",
      "[2130 / 2139] test loss: 0.514425, test accuracy: 0.859\n",
      "Eval time: 143.24 sec\n",
      "Saved checkpoint for step 37: ./ckpt_ResNet341D_ST/ckpt-36\n",
      "-------------------- Epoch 36--------------------\n",
      "[4930 / 4939] Training loss: 0.302130, Training acc: 0.887\n",
      "Training time: 1108.38 sec \n",
      "[2130 / 2139] test loss: 0.514537, test accuracy: 0.859\n",
      "Eval time: 134.34 sec\n",
      "Saved checkpoint for step 38: ./ckpt_ResNet341D_ST/ckpt-37\n",
      "-------------------- Epoch 37--------------------\n",
      "[4930 / 4939] Training loss: 0.302138, Training acc: 0.887\n",
      "Training time: 1128.63 sec \n",
      "[2130 / 2139] test loss: 0.514306, test accuracy: 0.860\n",
      "Eval time: 141.56 sec\n",
      "Saved checkpoint for step 39: ./ckpt_ResNet341D_ST/ckpt-38\n",
      "-------------------- Epoch 38--------------------\n",
      "[4930 / 4939] Training loss: 0.302039, Training acc: 0.887\n",
      "Training time: 1130.86 sec \n",
      "[2130 / 2139] test loss: 0.514086, test accuracy: 0.859\n",
      "Eval time: 143.66 sec\n",
      "Saved checkpoint for step 40: ./ckpt_ResNet341D_ST/ckpt-39\n",
      "-------------------- Epoch 39--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4930 / 4939] Training loss: 0.302038, Training acc: 0.888\n",
      "Training time: 1129.06 sec \n",
      "[2130 / 2139] test loss: 0.514251, test accuracy: 0.859\n",
      "Eval time: 139.98 sec\n",
      "Saved checkpoint for step 41: ./ckpt_ResNet341D_ST/ckpt-40\n",
      "-------------------- Epoch 40--------------------\n",
      "[4930 / 4939] Training loss: 0.302015, Training acc: 0.887\n",
      "Training time: 1134.15 sec \n",
      "[2130 / 2139] test loss: 0.513969, test accuracy: 0.859\n",
      "Eval time: 141.75 sec\n",
      "Saved checkpoint for step 42: ./ckpt_ResNet341D_ST/ckpt-41\n",
      "-------------------- Epoch 41--------------------\n",
      "[4930 / 4939] Training loss: 0.301892, Training acc: 0.887\n",
      "Training time: 1126.71 sec \n",
      "[2130 / 2139] test loss: 0.513679, test accuracy: 0.860\n",
      "Eval time: 137.14 sec\n",
      "Saved checkpoint for step 43: ./ckpt_ResNet341D_ST/ckpt-42\n",
      "-------------------- Epoch 42--------------------\n",
      "[4930 / 4939] Training loss: 0.301852, Training acc: 0.887\n",
      "Training time: 1121.86 sec \n",
      "[2130 / 2139] test loss: 0.513353, test accuracy: 0.860\n",
      "Eval time: 137.13 sec\n",
      "Saved checkpoint for step 44: ./ckpt_ResNet341D_ST/ckpt-43\n",
      "-------------------- Epoch 43--------------------\n",
      "[180 / 4939] Training loss: 0.300073, Training acc: 0.884\r"
     ]
    }
   ],
   "source": [
    "best_test_acc = 0.0\n",
    "for e in range(start_epoch, epochs):\n",
    "    correct, total_cnt, total_loss = 0.0, 0.0, 0.0\n",
    "    print('-'*20, 'Epoch ' + str(e) + '-'*20)\n",
    "    adjust_learning_rate(optimizer, e)\n",
    "    start = time.time()\n",
    "    for idx, (x, y) in enumerate(train_generator):               \n",
    "        #y_onehot = tf.one_hot(y, depth=n_classes)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss = loss_fn(y, y_pred)\n",
    "        \n",
    "        total_cnt += y_pred.shape[0]\n",
    "        y_pred_cls = tf.math.argmax(y_pred, axis=-1)\n",
    "        correct += tf.reduce_sum(tf.cast(tf.equal(y_pred_cls, y), tf.float32))\n",
    "        total_loss += loss * y_pred.shape[0]\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(\"[%d / %d] Training loss: %.6f, Training acc: %.3f\"%\n",
    "                  (idx+1, len(train_generator), total_loss / total_cnt, correct / total_cnt),end='\\r', flush=True)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    print(\"\")\n",
    "    print(\"Training time: %.2f sec \"%(time.time() - start))\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    correct, total_cnt, total_loss = 0.0, 0.0, 0.0\n",
    "    for idx, (x, y) in enumerate(test_generator):\n",
    "        y_pred = model(x, training=False)\n",
    "        y_pred_cls = tf.math.argmax(y_pred, axis=-1)\n",
    "        #y_onehot = tf.one_hot(y, depth=n_classes)\n",
    "        correct += tf.reduce_sum(tf.cast(tf.equal(y_pred_cls, y), tf.float32))\n",
    "        total_cnt += y_pred.shape[0]\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        total_loss += loss_fn(y, y_pred).numpy() * y_pred.shape[0]\n",
    "            \n",
    "        test_acc = correct / total_cnt\n",
    "        test_loss = total_loss / total_cnt\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(\"[%d / %d] test loss: %.6f, test accuracy: %.3f\"%\n",
    "                  (idx+1, len(test_generator), test_loss, test_acc),end='\\r', flush=True)\n",
    "    print(\"\")\n",
    "    print(\"Eval time: %.2f sec\"%(time.time() - start))\n",
    "    ckpt.step.assign_add(1)\n",
    "    if test_acc > best_test_acc:\n",
    "        save_path = manager.save()\n",
    "        print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04c989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0aa46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

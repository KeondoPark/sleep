{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e3cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:21:10.059206: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf076324",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c1c59162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Data.datagen' from '/home/keondopark/sleep/JupyterNotebooks/../Data/datagen.py'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nets\n",
    "from Data import datagen\n",
    "import importlib \n",
    "import resnet1D_Ahmed\n",
    "importlib.reload(datagen)  # Python 3.4+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a9b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df9c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_PATH = os.path.join('/home','aiot','data','origin_npy')\n",
    "save_signals_path_SC = os.path.join(PROCESSED_DATA_PATH,'signals_SC_filtered')\n",
    "save_annotations_path_SC = os.path.join(PROCESSED_DATA_PATH,'annotations_SC')\n",
    "save_signals_path_ST = os.path.join(PROCESSED_DATA_PATH,'signals_ST_filtered')\n",
    "save_annotations_path_ST = os.path.join(PROCESSED_DATA_PATH,'annotations_ST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457af95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_annotations_npy(dirname, filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    search_filename = filename.split('-')[0][:-2]\n",
    "    file_list = os.listdir(dirname)\n",
    "    filenames = [file for file in file_list if search_filename in file if file.endswith('.npy')]\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d64b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_HT1D = (3000,1)\n",
    "n_classes=6\n",
    "epochs = 50\n",
    "bs = 64\n",
    "BASE_LEARNING_RATE = 1e-3\n",
    "data_ratio = 0.25\n",
    "PREV_CNT = 10\n",
    "list_files_SC = [os.path.join(save_signals_path_SC, f) for f in os.listdir(save_signals_path_SC) if f.endswith('.npy')]\n",
    "list_files_ST = [os.path.join(save_signals_path_ST, f) for f in os.listdir(save_signals_path_ST) if f.endswith('.npy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccc54e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.7\n",
    "split_cnt_SC = int(train_test_split * len(list_files_SC))\n",
    "split_cnt_ST = int(train_test_split * len(list_files_ST))\n",
    "\n",
    "list_files_train = []\n",
    "list_files_test = []\n",
    "\n",
    "list_ann_files_train = []\n",
    "list_ann_files_test = []\n",
    "\n",
    "\n",
    "list_files_SC_train = np.random.choice(list_files_SC[:split_cnt_SC], int(0.25 * split_cnt_SC), replace=False)\n",
    "list_files_train += list_files_SC_train.tolist()\n",
    "for f in list_files_SC_train:\n",
    "    ann_file = match_annotations_npy(save_annotations_path_SC, f)\n",
    "    list_ann_files_train.append(os.path.join(save_annotations_path_SC, ann_file[0]))\n",
    "\n",
    "list_files_test += list_files_SC[split_cnt_SC:]\n",
    "\n",
    "for f in list_files_SC[split_cnt_SC:]:\n",
    "    ann_file = match_annotations_npy(save_annotations_path_SC, f)\n",
    "    list_ann_files_test.append(os.path.join(save_annotations_path_SC, ann_file[0]))\n",
    "\n",
    "\n",
    "list_files_ST_train = np.random.choice(list_files_ST[:split_cnt_ST], int(0.25 * split_cnt_ST), replace=False)\n",
    "list_files_train += list_files_ST_train.tolist()\n",
    "for f in list_files_ST_train:\n",
    "    ann_file = match_annotations_npy(save_annotations_path_ST, f)\n",
    "    list_ann_files_train.append(os.path.join(save_annotations_path_ST, ann_file[0]))\n",
    "\n",
    "list_files_test += list_files_ST[split_cnt_ST:]\n",
    "for f in list_files_ST[split_cnt_ST:]:\n",
    "    ann_file = match_annotations_npy(save_annotations_path_ST, f)\n",
    "    list_ann_files_test.append(os.path.join(save_annotations_path_ST, ann_file[0]))\n",
    "\n",
    "list_files_train2 = list_files_train[:1]\n",
    "list_ann_files_train2 = list_ann_files_train[:1]\n",
    "    \n",
    "    \n",
    "train_generator = datagen.DataGenerator2(list_files_train, list_ann_files_train, \n",
    "                          batch_size=bs, dim=dim_HT1D, n_classes=n_classes, shuffle=True, prev_cnt=PREV_CNT)\n",
    "test_generator = datagen.DataGenerator2(list_files_test, list_ann_files_test, \n",
    "                          batch_size=bs, dim=dim_HT1D, n_classes=n_classes, shuffle=False, prev_cnt=PREV_CNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb892a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, bi = next(iter(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8429866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_o = datagen.DataGenerator(list_files_train, list_ann_files_train, \n",
    "                          batch_size=bs, dim=dim_HT1D, n_classes=n_classes, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f37e1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, bi = next(iter(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7b142323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b48f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1446"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "739d7e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 0 0 1 1 1 1 2 2 1 0 0 0 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2]\n",
      "2 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3 [4 4 4 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "4 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "5 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "6 [0 1 1 0 0 0 1 0 0 0 0 1 1 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "7 [2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2 2 4 4 4]\n",
      "8 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "9 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "10 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "11 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "12 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 1 1 0 0 0 0 0 1 1]\n",
      "13 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "14 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 3 3 2 2 3 2 2 2 3\n",
      " 3 3 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3]\n",
      "15 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "16 [4 4 0 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 1 1 2 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0]\n",
      "17 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "18 [2 2 2 2 2 2 4 4 4 1 1 1 4 4 4 4 4 4 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "19 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "20 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "21 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "22 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "23 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "24 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "25 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1]\n",
      "26 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "27 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "28 [1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 3 2 2 2\n",
      " 2 3 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "29 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "30 [2 2 2 2 2 2 2 2 2 2 2 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2]\n",
      "31 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "32 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "33 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "34 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "35 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "36 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "37 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "38 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "39 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "40 [2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 4 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1\n",
      " 1 2 2 0 1 1 1 2 2 2 2 4 4 4 4 4 4 4 4 4 4 1 0 0 0 0 0]\n",
      "41 [0 0 0 0 0 0 0 1 1 1 0 1 1 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 1 1 2 2 2 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "42 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "43 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2 3 3 2 2 1 1 2 2 2 2 2 0 0 0 0\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 3 0 2 2 2 2 2 2 2 2 4 4 4 1]\n",
      "44 [1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "45 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "46 [2 1 1 0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 0 0 0 0 0 1 0\n",
      " 0 1 1 1 2 2 2 2 2 1 2 2 1 4 4 4 4 4 4 0 1 1 1 1 1 4 4]\n",
      "47 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "48 [2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3]\n",
      "49 [2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "50 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "51 [2 2 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2]\n",
      "52 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "53 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "54 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "55 [1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2 3 2 2 2 2 2 2 2 3 0]\n",
      "56 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "57 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "58 [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 2 1 2 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2]\n",
      "59 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "60 [4 4 4 4 4 4 4 4 4 4 1 1 2 2 2 2 4 4 4 4 4 4 1 1 1 1 1 1 2 2 2 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 1 2 2]\n",
      "61 [2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 3 3 2 2 3 2 3 2 2 3 3 2 2 3 3 3\n",
      " 3 3 3 3 2 2 3 3 3 3 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "62 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "63 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "64 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 1 1 1 1 2 2 1 2 2]\n",
      "65 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "66 [2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 3 2 3\n",
      " 3 2 2 1 1 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 0 0 0]\n",
      "67 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "68 [0 1 1 1 1 2 2 1 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 1 4 1 1 1 1 0 0 0\n",
      " 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 0 0 0 0 0 0 0]\n",
      "69 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "70 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "71 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "72 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "73 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "74 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "75 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "77 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "78 [4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "79 [2 2 2 2 2 2 2 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4]\n",
      "80 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "81 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "82 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "83 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "84 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "85 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "86 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "87 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "88 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "89 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "90 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "91 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "92 [2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "93 [3 2 2 2 2 2 2 2 3 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4]\n",
      "94 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "95 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "96 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 2 2 2 2 2 0 0 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2]\n",
      "97 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "98 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "99 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for x, y, bi in train_generator:\n",
    "    cnt += 1\n",
    "    if cnt < 100:\n",
    "        print(cnt, y)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a23c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = np.load(list_ann_files_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b36e90d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54662b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0 2 0 0 1 0 0 0 0 1 0 0 4 1 1 2 1 0 0 0 0 1 2 0 0 2 0 0 0 2 0 0 0 1 0 0 0\n",
      " 2 0 0 1 0 2 0 0 0 1 1 1 0 2 4 0 0 0 0 0 1 0 0 0 0 4 0]\n",
      "2 [2 0 1 0 0 0 0 0 1 0 0 2 2 0 2 2 2 0 1 4 2 2 0 0 2 2 0 0 2 2 0 2 0 0 1 0 2\n",
      " 2 1 1 0 0 4 1 1 1 4 0 2 1 0 0 0 0 2 1 0 0 2 0 0 1 1 0]\n",
      "3 [2 4 0 0 1 2 0 0 4 0 2 1 0 2 0 2 1 1 0 2 0 1 0 0 0 0 0 2 0 1 0 2 4 1 0 1 0\n",
      " 0 1 0 2 2 1 0 2 0 0 0 0 0 2 0 1 0 1 0 1 2 0 2 2 1 0 2]\n",
      "4 [2 0 2 0 1 0 0 0 0 4 0 0 0 1 0 0 2 0 0 1 1 1 0 0 2 0 2 4 4 1 0 0 1 0 1 0 0\n",
      " 4 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 2 1 1 2 0 2 1 0 0 0 0]\n",
      "5 [1 0 0 1 1 0 0 0 1 0 0 2 0 0 1 0 1 1 2 0 0 2 0 1 0 0 0 2 2 2 0 0 0 0 2 1 2\n",
      " 0 2 0 4 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 2 0 0 0]\n",
      "6 [0 0 0 0 0 0 0 0 0 2 1 0 0 0 4 0 0 0 0 0 1 0 0 1 0 0 0 2 0 0 0 1 0 0 0 2 0\n",
      " 1 1 0 0 0 0 0 0 2 0 0 0 2 0 0 2 0 1 4 1 0 0 1 0 0 0 0]\n",
      "7 [1 0 0 4 2 0 2 0 0 2 0 2 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 2 0 0 0 1 2 1 0 0\n",
      " 4 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 2 0 2 0 2]\n",
      "8 [0 0 0 0 0 0 0 2 4 1 0 0 1 0 0 0 1 0 0 0 2 1 4 0 4 2 1 0 2 0 4 4 0 1 0 0 0\n",
      " 0 4 0 2 4 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 2 1 0 0 0 0 0]\n",
      "9 [2 0 0 0 0 2 2 0 1 2 0 0 2 0 0 0 0 0 1 1 0 0 0 4 0 0 2 0 2 0 0 4 1 0 0 2 0\n",
      " 0 0 0 1 0 0 0 1 2 1 0 0 1 0 1 2 0 0 0 0 0 0 0 0 1 1 0]\n",
      "10 [1 2 4 0 0 1 0 0 1 0 1 4 0 0 4 1 0 0 2 2 0 0 1 1 2 0 0 2 0 2 1 0 1 2 0 1 2\n",
      " 4 0 0 4 0 0 0 0 0 1 0 0 0 0 0 2 2 1 0 1 1 0 0 4 0 0 0]\n",
      "11 [1 0 0 0 2 0 0 1 1 1 1 4 1 0 0 1 4 0 2 0 2 0 1 0 0 4 4 1 0 1 2 0 2 0 2 0 0\n",
      " 0 0 0 0 2 0 2 0 1 1 1 0 0 0 0 1 1 2 2 1 0 0 0 1 1 0 0]\n",
      "12 [0 0 0 0 0 0 2 0 2 2 2 1 0 2 4 0 0 0 0 4 0 2 0 1 1 0 2 0 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 2 0 0 0 0 0 0 2 0 0 0 1 1 0 4 0 4 1 0 2 0 2 0 0]\n",
      "13 [0 0 1 0 2 0 0 1 2 0 1 0 0 1 0 1 4 2 1 0 0 0 0 2 4 4 1 0 0 0 0 1 0 2 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 2 0 1 0 1 4 0 0 4 0 1 1 1 0 0 1 0 0]\n",
      "14 [1 2 0 1 0 0 0 0 2 4 0 0 2 0 1 1 0 0 0 2 2 2 0 0 0 0 0 0 1 0 0 2 1 2 0 0 0\n",
      " 0 0 0 1 2 0 0 0 0 0 0 1 1 0 0 0 4 1 1 2 0 4 4 0 1 0 0]\n",
      "15 [1 1 1 0 1 2 0 0 0 1 0 0 0 1 1 0 0 2 0 0 0 1 1 4 4 0 0 0 0 0 0 0 1 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 2 1 1 0 0 1 1 0 0 0 0 0 0 1 0 2 0]\n",
      "16 [1 0 1 0 0 0 0 2 2 0 1 2 4 1 0 4 1 4 1 0 4 1 1 0 0 0 0 0 1 0 4 0 1 2 1 0 0\n",
      " 0 0 0 4 2 0 0 0 0 0 0 0 0 2 1 2 1 1 0 1 1 0 0 0 0 1 4]\n",
      "17 [0 1 0 2 1 0 1 0 0 2 1 4 0 1 0 0 0 0 2 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 2 0 4 2 4 0 1 0 0 4 0 0 0 0 0 1 0 0 1 2 2 0 2 0 0 0 0]\n",
      "18 [2 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 2 0 2 1 4 2 0 0 2 2 0 1 0 0 4 4 0 2 0 0 0\n",
      " 0 4 0 0 0 1 1 0 0 0 4 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "19 [0 0 0 0 0 0 0 0 1 0 0 0 0 4 0 0 0 0 1 1 2 0 2 4 0 0 4 2 0 0 0 0 1 2 0 1 0\n",
      " 4 1 0 0 2 2 0 2 0 1 1 1 0 1 0 0 1 1 2 1 2 0 1 0 0 1 1]\n",
      "20 [0 0 0 4 1 0 0 0 0 0 1 0 1 2 1 0 0 1 0 0 0 0 0 1 0 4 0 0 0 2 0 2 1 0 0 0 0\n",
      " 2 0 0 0 0 0 2 0 0 2 1 0 0 1 0 2 1 2 1 0 4 1 0 0 2 0 4]\n",
      "21 [0 2 0 0 0 2 0 0 4 0 0 0 1 0 2 2 2 0 2 2 1 4 0 0 2 0 0 0 1 1 0 0 2 0 0 0 0\n",
      " 0 0 0 0 1 2 0 4 0 0 0 0 0 1 2 1 4 0 0 0 0 0 0 4 1 0 0]\n",
      "22 [2 0 0 2 0 0 1 1 4 0 0 0 2 2 0 0 0 0 0 0 0 4 1 0 0 0 0 0 1 0 0 0 4 0 2 0 0\n",
      " 0 4 0 1 0 2 0 2 0 0 0 0 4 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "23 [2 0 2 2 0 0 0 0 0 0 0 1 4 0 0 0 2 0 0 0 4 2 1 0 0 1 4 0 0 0 0 0 0 2 0 0 4\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 2 0 4 0 1 0 0 0 0 0 0 0 0]\n",
      "24 [0 0 1 0 4 4 0 4 2 4 1 0 4 2 0 1 1 0 0 1 1 1 0 0 0 1 2 1 0 0 0 0 0 1 0 2 0\n",
      " 0 0 1 2 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "25 [4 0 0 0 1 0 0 4 0 0 2 0 0 1 2 1 0 0 0 2 0 0 0 0 0 0 0 2 1 0 1 0 2 1 0 2 0\n",
      " 2 2 0 1 0 1 0 0 2 0 2 0 0 0 2 0 0 0 0 0 1 0 1 2 2 0 2]\n",
      "26 [0 0 2 0 0 2 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 2 1 0 0 0 2 0 0 2 2\n",
      " 0 0 1 0 0 0 0 0 2 0 0 1 0 5 2 0 1 0 0 0 2 1 0 0 0 0 1]\n",
      "27 [0 1 1 0 0 2 0 0 1 0 0 4 0 2 0 0 0 0 1 0 0 0 0 0 0 2 4 0 0 0 0 0 0 0 0 4 0\n",
      " 4 4 0 4 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 2 0 1 0 1 1 0 0]\n",
      "28 [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 4 1 0 1 0 1 0 1 0 2 1 2 0 0 0 0 1 0 2 2\n",
      " 0 0 2 1 0 0 0 0 0 1 1 2 0 1 1 0 0 0 2 1 2 0 0 0 0 1 0]\n",
      "29 [1 0 1 0 2 0 2 0 0 2 0 0 2 2 0 0 4 0 1 0 2 2 0 0 0 4 0 2 0 0 0 0 0 0 0 0 2\n",
      " 1 1 0 1 0 0 2 0 0 1 0 0 0 0 2 0 1 0 0 0 2 0 0 0 0 0 0]\n",
      "30 [4 0 0 1 0 0 1 0 4 1 0 0 0 2 2 0 4 2 1 0 1 0 1 0 0 0 0 0 0 2 0 0 0 0 2 0 0\n",
      " 0 2 0 0 1 1 1 0 0 2 2 0 4 2 0 1 4 1 0 0 0 0 2 1 0 2 0]\n",
      "31 [0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 0 0 0 1 0 4 0 0 0 0 0\n",
      " 2 2 0 1 4 0 0 0 1 1 0 2 2 2 2 0 0 0 2 2 1 2 0 2 1 0 2]\n",
      "32 [0 0 0 0 0 0 1 1 0 4 0 0 0 4 1 0 0 0 0 0 0 0 2 0 0 0 2 0 0 2 0 0 0 0 2 0 0\n",
      " 0 2 0 0 0 0 2 1 0 0 0 1 0 2 0 1 0 0 0 2 0 1 0 0 0 0 0]\n",
      "33 [0 1 0 2 0 0 0 1 2 1 0 0 0 2 0 2 0 2 4 0 0 2 1 2 0 0 0 0 0 2 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 0 0 0 0 1 2 0 0 0 0 0 1 0 1 2 1 0 0 2 0 0 0]\n",
      "34 [2 0 0 0 0 1 2 0 2 0 0 1 1 0 1 0 0 0 4 0 0 1 1 1 0 0 2 0 0 0 2 1 0 0 4 0 2\n",
      " 4 0 0 0 1 0 1 0 0 0 0 0 1 0 2 2 0 0 0 2 0 1 0 0 0 1 2]\n",
      "35 [0 0 0 2 0 0 2 0 2 0 0 0 0 2 0 0 4 1 1 0 0 2 0 1 1 2 0 4 1 2 0 0 0 2 0 0 0\n",
      " 0 2 0 0 0 0 0 0 0 0 2 1 0 2 0 0 0 0 4 0 0 0 1 1 2 0 0]\n",
      "36 [2 1 0 0 0 0 0 0 0 0 0 0 1 2 0 0 1 0 1 1 0 0 0 1 0 0 2 0 0 0 1 0 0 0 0 1 4\n",
      " 1 0 0 0 0 0 0 0 0 4 2 2 4 0 0 0 0 2 0 0 0 0 0 0 4 2 0]\n",
      "37 [2 0 0 0 1 1 2 0 2 0 1 0 0 0 2 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 4 1 0 2 0 1\n",
      " 0 0 0 4 0 0 0 0 0 0 0 2 2 1 4 2 1 0 1 0 1 1 0 1 0 0 0]\n",
      "38 [0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 2 1 2 1 0 0 0 0 2\n",
      " 2 0 1 0 0 1 4 1 1 0 0 1 0 0 0 0 0 1 4 1 1 0 1 0 0 0 0]\n",
      "39 [1 4 2 0 1 2 0 4 1 0 2 0 1 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 1 0 0 2 0 0 1 0 1\n",
      " 2 0 1 0 2 0 1 0 0 1 1 1 0 0 2 1 1 0 0 4 0 1 0 0 1 1 0]\n",
      "40 [4 0 0 0 0 2 0 0 2 0 0 1 0 0 0 0 2 1 0 0 0 1 2 0 0 2 0 4 1 0 0 0 0 1 0 0 0\n",
      " 1 1 0 0 0 0 0 2 1 0 2 2 0 0 2 0 0 0 0 2 2 0 0 0 1 0 0]\n",
      "41 [0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 1 2 0 1 1 0 1 0 0 2 0 0 0 0 0 0 0 0 2 0\n",
      " 2 1 0 0 1 1 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0]\n",
      "42 [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 2 0 1 0 0 0 0 0 0 1 0 0 2 0 0 0\n",
      " 2 0 0 0 0 4 1 0 0 2 0 2 0 0 0 0 0 0 0 0 0 2 0 4 2 2 0]\n",
      "43 [4 0 0 0 2 0 0 2 0 0 2 1 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 4 0 0 0 0 0 0 0 0 2 0 0 0 2 1 2 0 0 2 2 0 2 1 0]\n",
      "44 [0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 2 0 2 0 0 2 1 0 4 0 0 0 0 2 1 4 2 0 0 0 1\n",
      " 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 2 0]\n",
      "45 [1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 2 1 0 0 0 1 0 2 0 0 0 0 2 0 0 0 1 0 0 0 0 0\n",
      " 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      "46 [0 0 0 2 1 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 2 0\n",
      " 0 0 2 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1]\n",
      "47 [0 0 2 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 1 0\n",
      " 0 2 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      "48 [2 0 0 2 1 0 1 2 0 0 0 0 0 0 1 0 0 4 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 2 0 0\n",
      " 0 0 0 0 0 0 4 0 0 0 0 0 2 4 0 0 0 0 0 0 0 2 0 0 0 0 1]\n",
      "49 [2 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 4 2 0 0 2 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "50 [0 0 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 1 0 0 4 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 2 1 2]\n",
      "51 [0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 4 0 0 0 0 2 0 2 0 4 1 0 2 0 0 0 0 2\n",
      " 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 4 0 0 2]\n",
      "52 [2 1 2 4 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 4 0 0\n",
      " 4 0 0 1 2 0 1 0 2 4 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0]\n",
      "53 [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 4 2 0 0 2 0 1 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0\n",
      " 2 0 0 1 2 2 0 0 0 0 0 0 0 0 0 1 1 0 0 2 0 0 2 0 0 0 0]\n",
      "54 [0 0 0 0 2 0 0 0 2 0 0 2 0 0 2 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0\n",
      " 0 0 4 0 2 0 0 0 1 0 2 0 2 0 0 0 0 0 0 4 2 0 0 0 0 0 0]\n",
      "55 [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 4\n",
      " 0 1 0 1 0 0 2 0 0 1 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0]\n",
      "56 [0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 2 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 2 2 0 0 0 0 2 2 0 2 0 0 0 0 0 2 0 1 0 0 0 0 0 2 0 0]\n",
      "57 [0 0 0 0 0 0 2 2 0 0 0 2 0 0 0 0 2 0 0 1 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 2 2 0 0 0 0 0 0 0 2 0 2 0 0 0 0 1 0 0 1 0]\n",
      "58 [2 0 1 0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 0 2 0 0 2 2 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 1 0 0 0 0 4 0]\n",
      "59 [0 0 0 2 0 0 0 0 0 0 0 4 0 0 1 0 0 0 0 0 2 0 0 0 0 4 0 0 0 0 4 0 2 2 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      "60 [0 0 0 0 1 0 0 0 0 2 4 0 0 0 0 1 0 0 0 2 0 0 0 2 2 0 0 0 0 2 0 0 1 2 0 0 0\n",
      " 2 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 1 0 0 1 0 1 2 0 0]\n",
      "61 [2 0 0 0 0 0 0 0 0 2 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 4 0 2 0 0 0 0 0 1 0 0 0]\n",
      "62 [0 0 0 1 0 0 0 0 2 0 0 2 2 0 2 0 4 0 1 0 0 0 0 0 0 0 0 2 1 2 0 0 0 0 0 0 1\n",
      " 0 4 1 1 4 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 [0 2 0 2 2 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0\n",
      " 0 0 0 0 1 2 0 0 0 0 0 0 0 2 0 2 2 2 0 0 0 1 0 0 0 0 2]\n",
      "64 [1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n",
      " 0 0 0 0 1 0 2 2 0 4 2 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
      "65 [2 0 2 0 0 0 0 0 0 1 0 0 0 2 1 0 0 0 0 0 0 0 0 0 2 0 2 4 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 2 0 1 0 0 0 0 0 0 0 0 0 1 0 0 2 0 4 0 2 2 0]\n",
      "66 [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 4 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 2 2 1 0 0 2 0 0 4 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0]\n",
      "67 [0 0 0 2 0 0 0 0 0 0 2 1 0 0 4 0 2 0 2 2 2 0 0 0 0 2 0 0 4 1 2 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 1 0 2 0 0 0 0 0 0 0 0 2 0 0 2 1 0 0 2 0 0]\n",
      "68 [2 0 0 0 2 0 0 4 0 0 0 4 2 4 2 0 0 0 0 0 0 2 0 0 0 0 4 0 4 0 0 0 2 0 0 4 0\n",
      " 2 2 1 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0 0 2 2 0 0 2 1 1 0]\n",
      "69 [0 4 0 0 0 2 0 2 0 1 0 0 4 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 2 0 0 0 0 2 0 0 2 0 1 0 0 2 2 1 0 0 0 0 0 0]\n",
      "70 [0 1 0 2 4 0 2 0 0 0 4 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 2 0 0 0 0 2 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 0 0 0 2 1 1 0 2 2 0 0 0 0 0 0 0 4 2 0 2]\n",
      "71 [0 0 2 0 0 0 0 0 0 2 2 0 0 2 0 0 4 0 0 0 0 0 0 1 0 0 0 2 2 0 0 4 1 0 0 2 0\n",
      " 0 0 2 2 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 2 0 0 4]\n",
      "72 [0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 4 0 0 0 0 0 0 0 0 0 2 1]\n",
      "73 [0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 0 0 2 2 0 1 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0\n",
      " 0 2 0 2 0 2 0 0 0 0 2 0 0 1 2 0 0 2 0 0 0 2 1 0 2 0 2]\n",
      "74 [4 0 0 0 0 0 0 0 4 0 2 0 0 0 0 1 0 2 0 1 0 0 0 0 0 4 4 0 0 0 0 1 1 0 0 2 0\n",
      " 0 0 0 0 0 0 0 0 1 2 0 2 1 2 0 0 0 2 4 0 0 0 0 0 0 2 0]\n",
      "75 [0 0 0 0 1 0 4 0 2 2 0 0 2 0 0 2 0 2 0 2 0 2 0 1 0 0 0 0 1 4 0 0 0 2 0 0 0\n",
      " 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 4 0 4 0 0 0]\n",
      "76 [0 0 0 0 1 1 1 0 0 2 0 0 2 0 0 0 0 2 0 0 0 4 2 0 1 1 1 0 0 2 2 0 0 0 0 2 0\n",
      " 0 0 0 2 0 0 0 1 0 1 1 0 0 0 0 4 0 0 0 0 2 0 2 0 0 0 0]\n",
      "77 [0 0 0 0 0 1 2 0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 2 0 0 0 0 0 0 2\n",
      " 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "78 [0 0 2 0 2 0 2 0 0 0 0 1 2 0 0 4 0 4 2 0 2 2 0 0 2 0 0 0 0 0 4 0 2 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 2 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
      "79 [0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 4 0 0 2]\n",
      "80 [4 0 2 0 0 2 0 2 0 0 0 0 0 0 2 0 0 2 0 0 2 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "81 [0 0 0 0 2 2 0 1 1 0 0 2 0 0 0 1 0 1 2 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 0 0 0 2 0 0 0 1 0 2 4 0 1 0 0 2 1 0 0 0 0 0 0 0]\n",
      "82 [0 0 0 0 2 0 2 2 0 0 0 0 0 1 0 0 2 2 0 0 0 2 2 0 0 0 4 2 0 0 0 2 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 3 0 4 1 0 0 0 0 4 1 2 0 0 0 0 0 0]\n",
      "83 [0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 2 3 0 2\n",
      " 2 0 2 0 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 4]\n",
      "84 [2 0 0 0 4 0 0 2 2 0 0 0 2 0 0 2 0 0 0 0 4 0 0 2 0 2 4 0 0 0 2 0 0 2 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 0 2 0 0 4 2 0 0 0 0 3 1 0 0 0 2 0]\n",
      "85 [0 0 4 0 0 0 2 0 2 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 1 0 0 0 0 0\n",
      " 1 0 2 0 4 2 2 2 0 4 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0]\n",
      "86 [0 0 0 0 2 2 2 0 2 2 2 0 4 0 1 0 0 0 0 2 0 0 0 1 0 2 2 0 0 0 0 2 2 0 4 0 0\n",
      " 4 0 2 0 0 2 0 0 0 0 2 0 0 0 1 0 0 0 0 0 2 0 4 0 0 0 1]\n",
      "87 [0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 2 0 0 4 0 0 4 2 0 4 3 2 2 0 0 4 0 0 2 0 4 2\n",
      " 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 1 2 0 4 0 0 0 0 0 0 0 2]\n",
      "88 [0 4 0 0 4 0 0 0 4 0 4 0 4 0 2 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n",
      " 0 0 2 0 0 0 0 0 2 0 0 0 0 0 4 0 0 0 0 0 0 0 3 0 2 2 0]\n",
      "89 [0 0 0 2 0 0 2 2 0 0 4 0 2 1 2 0 0 0 0 2 2 0 0 0 2 0 0 2 0 0 0 0 2 0 0 2 0\n",
      " 2 0 0 0 0 2 0 0 0 0 0 0 1 2 0 0 0 1 0 2 2 0 0 2 0 0 0]\n",
      "90 [0 0 0 0 0 4 0 0 0 2 1 0 0 2 0 0 0 0 2 2 0 0 0 0 2 0 0 0 0 0 1 2 0 4 0 4 0\n",
      " 2 0 0 0 0 0 0 0 2 4 1 0 2 0 0 0 0 0 0 0 4 0 0 0 0 2 2]\n",
      "91 [0 2 2 2 4 0 0 0 0 0 2 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 1 0 4 0 0 0 1 0 0 2 0\n",
      " 1 0 2 0 2 4 0 0 2 2 4 0 0 0 2 1 4 0 4 0 0 0 0 4 2 0 1]\n",
      "92 [0 0 1 4 4 0 4 0 0 0 0 0 0 0 0 0 0 1 2 2 0 2 0 0 2 0 4 0 1 2 0 0 0 0 2 0 0\n",
      " 0 0 0 0 2 1 0 1 2 0 1 0 4 4 0 0 0 0 0 2 0 0 2 0 2 0 0]\n",
      "93 [2 2 0 0 0 0 0 2 2 4 0 4 0 0 0 0 0 1 0 0 0 0 2 0 0 2 0 0 2 0 0 2 0 2 0 0 2\n",
      " 0 2 0 0 0 0 0 2 2 2 2 4 0 1 0 0 0 0 0 0 0 0 2 0 0 0 2]\n",
      "94 [2 2 0 0 0 0 0 0 0 4 0 2 0 0 2 0 0 2 0 2 0 0 0 4 2 0 2 0 0 0 0 0 2 0 2 0 2\n",
      " 2 0 2 0 2 0 2 4 0 0 0 1 0 0 0 0 0 0 2 2 0 0 1 2 0 2 2]\n",
      "95 [4 0 0 2 1 0 0 0 2 2 0 0 0 2 0 0 4 0 0 0 0 0 0 0 0 0 0 4 4 2 2 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 4 0 0 2 0 0 0 2 0 2 0 2 0 0 0 0 4 0 0 0 0]\n",
      "96 [2 4 2 1 2 0 2 0 1 0 0 0 2 4 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 2 0 0 0 0\n",
      " 0 0 2 0 2 0 0 3 0 0 1 2 2 0 0 0 0 0 0 0 0 2 0 1 0 2 2]\n",
      "97 [0 4 4 0 0 2 0 0 0 2 2 0 0 2 0 0 2 0 0 0 0 2 0 0 0 0 2 4 2 0 0 0 2 4 0 0 0\n",
      " 0 1 0 2 0 4 2 0 0 0 2 0 1 0 0 0 0 0 1 0 0 0 2 0 4 2 4]\n",
      "98 [0 4 0 0 0 0 2 2 0 2 0 4 2 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 1 2 0 0 4\n",
      " 0 0 1 0 0 0 0 2 2 0 2 0 4 2 1 2 4 0 1 0 0 0 0 0 0 0 0]\n",
      "99 [4 2 0 0 0 1 2 4 0 4 0 2 0 0 2 0 4 0 0 0 1 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 0 4 0 1 0 0 0 0 2 0 0 0 4 0 1 0 0 0 2 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for x, y in train_generator_o:\n",
    "    cnt += 1\n",
    "    if cnt < 100:\n",
    "        print(cnt, y)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ddc8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cnt_class = defaultdict(int)\n",
    "for x, y in train_generator_o:\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    for i, cnt in zip(unique, counts):\n",
    "        cnt_class[i] += cnt\n",
    "cnt_class_np = np.zeros((n_classes,))\n",
    "for i in range(n_classes):\n",
    "    cnt_class_np[i] = cnt_class[i]\n",
    "class_weight = 0.1 * np.ones((n_classes,))\n",
    "class_weight[:n_classes-1] = sum(cnt_class_np[:n_classes-1])/(n_classes * cnt_class_np[:n_classes-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a24734d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49058.,  5067., 14266.,  3202.,  5844.,   126.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array([49845.,  5164., 13992.,  2675.,  5113.,   139.])\n",
    "cnt_class_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7672d255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1225.0625"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cnt_class_np)/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9ab09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weight\n",
    "# Tested loss with class weight, but doesn't improve the accuracy\n",
    "\n",
    "from collections import defaultdict\n",
    "cnt_class = defaultdict(int)\n",
    "for x, y, batch_idx in train_generator:\n",
    "    y1 = y\n",
    "    if batch_idx > 0:\n",
    "        y1 = y[PREV_CNT:]\n",
    "    unique, counts = np.unique(y1, return_counts=True)\n",
    "    for i, cnt in zip(unique, counts):\n",
    "        cnt_class[i] += cnt\n",
    "cnt_class_np = np.zeros((n_classes,))\n",
    "for i in range(n_classes):\n",
    "    cnt_class_np[i] = cnt_class[i]\n",
    "class_weight = 0.1 * np.ones((n_classes,))\n",
    "class_weight[:n_classes-1] = sum(cnt_class_np[:n_classes-1])/(n_classes * cnt_class_np[:n_classes-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d3387e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49640.,  5117., 14360.,  3228.,  5909.,   150.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array([49640.,  5117., 14360.,  3228.,  5909.,   150.])\n",
    "cnt_class_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aaba5bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 58)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_ann_files_train), len(list_ann_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4cad716d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aiot/data/origin_npy/annotations_SC/SC4261FM-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4661EJ-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4722EM-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4641EP-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4091EC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4742EC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4021EH-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4451FY-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4532EV-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4042EC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4571FV-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4502EM-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4401EC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4732EJ-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4461FA-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4591GY-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4381FC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4672GV-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4002EC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4481FV-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4331FV-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4581GM-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4542FW-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4402EW-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4281GC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_SC/SC4822GC-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_ST/ST7172JA-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_ST/ST7101JE-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_ST/ST7152JA-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_ST/ST7121JE-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_ST/ST7192JR-Hypnogram.npy',\n",
       " '/home/aiot/data/origin_npy/annotations_ST/ST7211JJ-Hypnogram.npy']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ann_files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1bcb59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.Conv1DASPP_prev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47dd3fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 6), dtype=float32, numpy=\n",
       "array([[0.16973524, 0.16630745, 0.17377722, 0.16021399, 0.17130591,\n",
       "        0.15866019],\n",
       "       [0.16921692, 0.16681409, 0.17344151, 0.16024154, 0.1706118 ,\n",
       "        0.15967411],\n",
       "       [0.16902594, 0.16752543, 0.17219436, 0.16109498, 0.17112027,\n",
       "        0.159039  ],\n",
       "       [0.16920619, 0.1661851 , 0.17330651, 0.1603453 , 0.17140149,\n",
       "        0.15955546],\n",
       "       [0.16931668, 0.16737747, 0.17394885, 0.16013874, 0.17098126,\n",
       "        0.158237  ],\n",
       "       [0.16844678, 0.16701986, 0.17322499, 0.16077387, 0.17054735,\n",
       "        0.15998715],\n",
       "       [0.16878071, 0.16637264, 0.17452267, 0.1602637 , 0.16990496,\n",
       "        0.1601553 ],\n",
       "       [0.16927868, 0.1670752 , 0.17414981, 0.16002983, 0.1702515 ,\n",
       "        0.15921493],\n",
       "       [0.16942756, 0.16713938, 0.17369036, 0.16060594, 0.17013408,\n",
       "        0.15900266],\n",
       "       [0.16924617, 0.1672862 , 0.17300035, 0.16008957, 0.17148034,\n",
       "        0.15889736],\n",
       "       [0.16988957, 0.1674604 , 0.1722386 , 0.16028856, 0.17070693,\n",
       "        0.15941593],\n",
       "       [0.16890644, 0.16786733, 0.17266683, 0.16075343, 0.16994348,\n",
       "        0.15986255],\n",
       "       [0.16971035, 0.1665824 , 0.17290454, 0.16102408, 0.1706165 ,\n",
       "        0.15916212],\n",
       "       [0.16816227, 0.16712332, 0.17219843, 0.16135302, 0.17100865,\n",
       "        0.1601543 ],\n",
       "       [0.16961277, 0.16631545, 0.17361024, 0.16051517, 0.17075008,\n",
       "        0.15919636],\n",
       "       [0.1707512 , 0.1672807 , 0.17342567, 0.15943024, 0.17037693,\n",
       "        0.1587353 ],\n",
       "       [0.16933425, 0.16710941, 0.17401464, 0.16006404, 0.16993563,\n",
       "        0.15954202],\n",
       "       [0.17010605, 0.16727072, 0.17253411, 0.160114  , 0.17030546,\n",
       "        0.15966964],\n",
       "       [0.16994861, 0.16689768, 0.1725934 , 0.16024448, 0.17106992,\n",
       "        0.15924592],\n",
       "       [0.1699835 , 0.16588677, 0.17289366, 0.16099274, 0.17205144,\n",
       "        0.15819193],\n",
       "       [0.16856985, 0.16646886, 0.17341913, 0.16087608, 0.17122914,\n",
       "        0.1594369 ],\n",
       "       [0.16959614, 0.16656588, 0.17346822, 0.16066958, 0.17065564,\n",
       "        0.1590446 ],\n",
       "       [0.16960533, 0.16718142, 0.17329882, 0.15997246, 0.17080295,\n",
       "        0.15913905],\n",
       "       [0.16983874, 0.166091  , 0.17336142, 0.16022988, 0.17026383,\n",
       "        0.16021514],\n",
       "       [0.16982742, 0.1664377 , 0.17387664, 0.1596094 , 0.17118701,\n",
       "        0.1590618 ],\n",
       "       [0.16945216, 0.1674703 , 0.17269552, 0.16133812, 0.17020155,\n",
       "        0.1588423 ],\n",
       "       [0.16889971, 0.16657427, 0.17287578, 0.16170895, 0.17135659,\n",
       "        0.15858471],\n",
       "       [0.1697762 , 0.16692711, 0.17290255, 0.16050956, 0.17033626,\n",
       "        0.15954837],\n",
       "       [0.16991808, 0.16675125, 0.17289951, 0.16102648, 0.17020987,\n",
       "        0.15919484],\n",
       "       [0.16928229, 0.16761595, 0.17250581, 0.16059062, 0.17123549,\n",
       "        0.15876982],\n",
       "       [0.1691359 , 0.16649811, 0.17313105, 0.16084994, 0.17181903,\n",
       "        0.15856592],\n",
       "       [0.1688416 , 0.16604207, 0.17382428, 0.16092052, 0.17141968,\n",
       "        0.1589518 ],\n",
       "       [0.16952227, 0.16688727, 0.1737192 , 0.15964493, 0.17048512,\n",
       "        0.15974116],\n",
       "       [0.16981417, 0.16673565, 0.17227024, 0.1609369 , 0.17083335,\n",
       "        0.1594097 ],\n",
       "       [0.16914028, 0.16780716, 0.17284578, 0.16105342, 0.16945916,\n",
       "        0.15969414],\n",
       "       [0.16967046, 0.16643833, 0.1727885 , 0.15966986, 0.17166406,\n",
       "        0.1597688 ],\n",
       "       [0.16909195, 0.16687873, 0.17407463, 0.16060148, 0.17026098,\n",
       "        0.15909222],\n",
       "       [0.16981947, 0.16714722, 0.1721459 , 0.16005966, 0.17122343,\n",
       "        0.15960428],\n",
       "       [0.16936204, 0.16704033, 0.17347626, 0.15881553, 0.17133117,\n",
       "        0.15997466],\n",
       "       [0.16963728, 0.16705827, 0.17229342, 0.15971248, 0.17060362,\n",
       "        0.16069494],\n",
       "       [0.16933079, 0.16669263, 0.17261073, 0.1608361 , 0.17103429,\n",
       "        0.15949546],\n",
       "       [0.16939017, 0.16714466, 0.17419668, 0.16075422, 0.16997252,\n",
       "        0.15854171],\n",
       "       [0.17016433, 0.16646986, 0.17400204, 0.16083676, 0.16957225,\n",
       "        0.15895478],\n",
       "       [0.16828106, 0.16658418, 0.17354678, 0.16151454, 0.17088409,\n",
       "        0.15918934],\n",
       "       [0.16928442, 0.16694734, 0.17240955, 0.1604069 , 0.17101341,\n",
       "        0.15993838],\n",
       "       [0.17015524, 0.16651279, 0.17376126, 0.15986554, 0.1697392 ,\n",
       "        0.15996596],\n",
       "       [0.16939303, 0.16600771, 0.17320229, 0.16073059, 0.17038926,\n",
       "        0.1602771 ],\n",
       "       [0.16965917, 0.16730669, 0.17237702, 0.16081282, 0.17104246,\n",
       "        0.1588018 ],\n",
       "       [0.16970554, 0.16641441, 0.17237306, 0.16219549, 0.16976768,\n",
       "        0.1595438 ],\n",
       "       [0.16971673, 0.16554715, 0.17275454, 0.16168165, 0.1698222 ,\n",
       "        0.16047771],\n",
       "       [0.17061475, 0.16675557, 0.17261013, 0.15922664, 0.17133403,\n",
       "        0.15945888],\n",
       "       [0.17025904, 0.16675279, 0.17264979, 0.16037169, 0.17013341,\n",
       "        0.15983324],\n",
       "       [0.16851728, 0.16826342, 0.17309447, 0.15985237, 0.17059611,\n",
       "        0.15967636],\n",
       "       [0.17079756, 0.16689128, 0.17273863, 0.15950327, 0.17126901,\n",
       "        0.15880021],\n",
       "       [0.16791229, 0.16522406, 0.1737748 , 0.1614384 , 0.1715444 ,\n",
       "        0.16010602],\n",
       "       [0.16933869, 0.16698918, 0.173178  , 0.15918505, 0.17174725,\n",
       "        0.1595619 ],\n",
       "       [0.1692529 , 0.16717602, 0.17339146, 0.15987532, 0.17065398,\n",
       "        0.15965028],\n",
       "       [0.16948962, 0.16662353, 0.17261669, 0.16058585, 0.17148642,\n",
       "        0.15919793],\n",
       "       [0.1695503 , 0.16651142, 0.1741982 , 0.16036189, 0.17048566,\n",
       "        0.1588925 ],\n",
       "       [0.1694323 , 0.16806446, 0.1727826 , 0.16048187, 0.17063543,\n",
       "        0.15860331],\n",
       "       [0.16827118, 0.16658741, 0.17277034, 0.1610688 , 0.1706713 ,\n",
       "        0.16063099],\n",
       "       [0.17012803, 0.16627061, 0.17312358, 0.160795  , 0.17124225,\n",
       "        0.15844047],\n",
       "       [0.16770518, 0.166309  , 0.17363256, 0.16077174, 0.17186731,\n",
       "        0.15971419],\n",
       "       [0.16970462, 0.16611943, 0.17308344, 0.160391  , 0.17048281,\n",
       "        0.16021864]], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((64,3000,1))\n",
    "x = tf.convert_to_tensor(x)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5f391259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv1daspp_prev_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_block_79 (conv1d_bloc multiple                  320       \n",
      "_________________________________________________________________\n",
      "conv1d_block_80 (conv1d_bloc multiple                  10560     \n",
      "_________________________________________________________________\n",
      "conv1d_block_81 (conv1d_bloc multiple                  20800     \n",
      "_________________________________________________________________\n",
      "conv1d_block_82 (conv1d_bloc multiple                  41280     \n",
      "_________________________________________________________________\n",
      "conv1d_block_83 (conv1d_bloc multiple                  41280     \n",
      "_________________________________________________________________\n",
      "conv1d_block_84 (conv1d_bloc multiple                  41280     \n",
      "_________________________________________________________________\n",
      "conv1d_block_85 (conv1d_bloc multiple                  41280     \n",
      "_________________________________________________________________\n",
      "conv1d_block_86 (conv1d_bloc multiple                  41280     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "multihead_attention__feat_5  multiple                  12480     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           multiple                  4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv1d_block_87 (conv1d_bloc multiple                  492800    \n",
      "_________________________________________________________________\n",
      "conv1d_block_88 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "conv1d_block_89 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv1d_block_90 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "conv1d_block_91 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "conv1d_block_92 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv1d_block_93 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "conv1d_block_94 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "conv1d_block_95 (conv1d_bloc multiple                  328960    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  52230     \n",
      "=================================================================\n",
      "Total params: 3,431,686\n",
      "Trainable params: 3,425,990\n",
      "Non-trainable params: 5,696\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7e79fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_lr(epoch):\n",
    "    lr = BASE_LEARNING_RATE\n",
    "    for _ in range(epoch // 10):\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    optimizer.learning_rate = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f28f59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        bs = y_pred.shape[0]\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        #loss = -K.sum(loss, -1)\n",
    "        loss = -K.sum(loss) / bs\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "035a46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "#loss_fn = weighted_categorical_crossentropy(weights=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "40130015",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpt_Advanced_Conv1D', max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4ed5b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "#if manager.latest_checkpoint:\n",
    "#    ckpt.restore(manager.latest_checkpoint)\n",
    "#    start_epoch = ckpt.step.numpy()-1\n",
    "best_test_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "76064428",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss_value = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))    \n",
    "    return loss_value, y_pred\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    y_pred = model(x, training=False)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ceee5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 10, 16,  2, 27, 25, 29, 23,  8,  3, 20,  6, 46, 22, 24, 26, 33,\n",
       "        0, 41, 19, 13,  4,  9, 12, 14, 28, 21, 42, 31, 35, 17, 18, 44, 40,\n",
       "        5, 39,  7, 45, 30, 43,  1, 34, 36, 32, 38, 37, 15])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.batch_indexes[train_generator.file_indexes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d2271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Epoch 0--------------------\n",
      "[1211 / 1211] Training loss: 1.572030, Training acc: 0.619\n",
      "Training loss: 1.572030, Training acc: 0.619\n",
      "Training time: 178.18 sec \n",
      "--------------------Epoch 1--------------------\n",
      "[1211 / 1211] Training loss: 0.938574, Training acc: 0.687\n",
      "Training loss: 0.938574, Training acc: 0.687\n",
      "Training time: 178.11 sec \n",
      "--------------------Epoch 2--------------------\n",
      "[1211 / 1211] Training loss: 0.957514, Training acc: 0.671\n",
      "Training loss: 0.957514, Training acc: 0.671\n",
      "Training time: 179.98 sec \n",
      "--------------------Epoch 3--------------------\n",
      "[1211 / 1211] Training loss: 0.801773, Training acc: 0.719\n",
      "Training loss: 0.801773, Training acc: 0.719\n",
      "Training time: 185.13 sec \n",
      "--------------------Epoch 4--------------------\n",
      "[1211 / 1211] Training loss: 0.730770, Training acc: 0.737\n",
      "Training loss: 0.730770, Training acc: 0.737\n",
      "Training time: 175.08 sec \n",
      "--------------------Epoch 5--------------------\n",
      "[1211 / 1211] Training loss: 0.730808, Training acc: 0.743\n",
      "Training loss: 0.730808, Training acc: 0.743\n",
      "Training time: 178.02 sec \n",
      "--------------------Epoch 6--------------------\n",
      "[1211 / 1211] Training loss: 0.629159, Training acc: 0.773\n",
      "Training loss: 0.629159, Training acc: 0.773\n",
      "Training time: 178.13 sec \n",
      "--------------------Epoch 7--------------------\n",
      "[1211 / 1211] Training loss: 0.562749, Training acc: 0.793\n",
      "Training loss: 0.562749, Training acc: 0.793\n",
      "Training time: 175.08 sec \n",
      "--------------------Epoch 8--------------------\n",
      "[1211 / 1211] Training loss: 0.541541, Training acc: 0.800\n",
      "Training loss: 0.541541, Training acc: 0.800\n",
      "Training time: 179.50 sec \n",
      "--------------------Epoch 9--------------------\n",
      "[1211 / 1211] Training loss: 0.492718, Training acc: 0.811\n",
      "Training loss: 0.492718, Training acc: 0.811\n",
      "Training time: 178.10 sec \n",
      "[2139 / 2139] test loss: 0.979984, test accuracy: 0.732\n",
      "test loss: 0.979984, test acc: 0.732\n",
      "Eval time: 93.34 sec\n",
      "Saved checkpoint for step 11: ./ckpt_Advanced_Conv1D/ckpt-1\n",
      "--------------------Epoch 10--------------------\n",
      "[1211 / 1211] Training loss: 0.452570, Training acc: 0.824\n",
      "Training loss: 0.452570, Training acc: 0.824\n",
      "Training time: 172.75 sec \n",
      "--------------------Epoch 11--------------------\n",
      "[1211 / 1211] Training loss: 0.423556, Training acc: 0.834\n",
      "Training loss: 0.423556, Training acc: 0.834\n",
      "Training time: 183.50 sec \n",
      "--------------------Epoch 12--------------------\n",
      "[730 / 1211] Training loss: 0.398290, Training acc: 0.842\r"
     ]
    }
   ],
   "source": [
    "for e in range(start_epoch, epochs):\n",
    "    correct, total_cnt, total_loss = 0.0, 0.0, 0.0\n",
    "    print('-'*20 + 'Epoch ' + str(e) + '-'*20)\n",
    "    adjust_learning_rate(optimizer, e)\n",
    "    start = time.time()\n",
    "    for idx, (x, y) in enumerate(train_generator):   \n",
    "        #print(x.shape)\n",
    "        #loss, y_pred = train_step(x, y)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss_value = loss_fn(y, y_pred)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))    \n",
    "        loss = loss_value\n",
    "\n",
    "        total_cnt += y_pred.shape[0]\n",
    "        y_pred_cls = tf.math.argmax(y_pred, axis=-1)\n",
    "        correct += tf.reduce_sum(tf.cast(tf.equal(y_pred_cls, y), tf.float32))\n",
    "        total_loss += loss * y_pred.shape[0]\n",
    "        if (idx + 1) % 10 == 0 or idx+1 == len(train_generator):\n",
    "            print(\"[%d / %d] Training loss: %.6f, Training acc: %.3f\"%\n",
    "                  (idx+1, len(train_generator), total_loss / total_cnt, correct / total_cnt),end='\\r', flush=True)\n",
    "        \n",
    "    print(\"\")\n",
    "    print(\"Training loss: %.6f, Training acc: %.3f\"%(total_loss / total_cnt, correct / total_cnt))\n",
    "    print(\"Training time: %.2f sec \"%(time.time() - start))\n",
    "    ckpt.step.assign_add(1)\n",
    "    \n",
    "    if e+1 >= 10 and (e+1) % 5 == 0:\n",
    "        start = time.time()\n",
    "        \n",
    "        correct, total_cnt, total_loss = 0.0, 0.0, 0.0\n",
    "        for idx, (x, y) in enumerate(test_generator):\n",
    "            #y_pred = model(x, training=False)\n",
    "            \n",
    "            y_pred = test_step(x, y)\n",
    "            y_pred_cls = tf.math.argmax(y_pred, axis=-1)\n",
    "            correct += tf.reduce_sum(tf.cast(tf.equal(y_pred_cls, y), tf.float32))\n",
    "            total_cnt += y_pred.shape[0]\n",
    "            y = tf.cast(y, dtype=tf.int32)\n",
    "            y_onehot = tf.one_hot(y, depth=n_classes)\n",
    "            total_loss += loss_fn(y, y_pred).numpy() * y_pred.shape[0]\n",
    "            #total_loss += loss_fn(y_onehot, y_pred).numpy() * y_pred.shape[0]\n",
    "                \n",
    "            test_acc = correct / total_cnt\n",
    "            test_loss = total_loss / total_cnt\n",
    "            if (idx + 1) % 10 == 0 or idx+1 == len(test_generator):\n",
    "                print(\"[%d / %d] test loss: %.6f, test accuracy: %.3f\"%\n",
    "                    (idx+1, len(test_generator), test_loss, test_acc),end='\\r', flush=True)\n",
    "            \n",
    "        print(\"\")\n",
    "        print(\"test loss: %.6f, test acc: %.3f\"%(test_loss, test_acc))\n",
    "        print(\"Eval time: %.2f sec\"%(time.time() - start))\n",
    "        \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total_cnt, total_loss = 0.0, 0.0, 0.0\n",
    "confusion_matrix = np.zeros((n_classes,n_classes))\n",
    "for idx, (x, y) in enumerate(test_generator):\n",
    "    y_pred = model(x, training=False)\n",
    "    y_pred_cls = tf.math.argmax(y_pred, axis=-1)\n",
    "    correct += tf.reduce_sum(tf.cast(tf.equal(y_pred_cls, y), tf.float32))\n",
    "    total_cnt += y_pred.shape[0]\n",
    "    y = tf.cast(y, dtype=tf.int32)    \n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            confusion_matrix[i,j] += np.sum((y_pred_cls.numpy()==i) * (y.numpy()==j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabe1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print_ln = \"\"\n",
    "    for j in range(n_classes):\n",
    "        print_ln += \"%.3f \"%(confusion_matrix[i,j] / np.sum(confusion_matrix[i]))\n",
    "        #print_ln += \"%d \"%(confusion_matrix[i,j])\n",
    "    print(print_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(20)\n",
    "np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea077a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = np.array([[0,0,1],[1,0,0],[0,1,0], [3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pc.shape[0]\n",
    "x = np.tile(np.expand_dims(pc,1), [1,n,1])\n",
    "y = np.empty((n,n,3))\n",
    "y[:] = np.tile(np.expand_dims(pc,0), [n,1,1])\n",
    "dist = np.sum((x - y) ** 2, axis=2) ** 0.5 # n by n matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de208c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_list = []\n",
    "thr = 2\n",
    "for i in range(1, n):    \n",
    "    included = False\n",
    "    for inst_set in instances_list:\n",
    "        if i in inst_set:\n",
    "            included = True\n",
    "            break\n",
    "    if not included:\n",
    "        close_pts = set()           \n",
    "        q = [i]\n",
    "        while q:\n",
    "            j = q.pop()\n",
    "            #if j in close_pts: continue\n",
    "            new_pts = set(np.where(dist[j,:] < thr)[0])\n",
    "            add_pts = new_pts - close_pts\n",
    "            q += list(add_pts)\n",
    "            close_pts = close_pts.union(add_pts)\n",
    "        \n",
    "        instances_list.append(close_pts)\n",
    "centroids = []\n",
    "for s in instances_list:\n",
    "    cent = np.mean(pc[list(s),:], axis=0)\n",
    "    centroids.append(cent)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, instances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1,2,3,4],[5,6,7,8],[4,3,2,1]], [[1,2,3,4],[5,9,7,8],[4,3,2,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a7aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5315041",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,:,0] == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((x[:,:,0] == 5) * (x[:,:,1] == 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29573dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((2,3000))\n",
    "b = np.ones(2)\n",
    "c = 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)\n",
    "df['b'] = b\n",
    "df['c'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c11101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.random.random((2,3000))\n",
    "e = np.ones(2)*2\n",
    "f = 'def'\n",
    "df2 = pd.DataFrame(d)\n",
    "df2['b'] = e\n",
    "df2['c'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7846010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb59566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62af67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
